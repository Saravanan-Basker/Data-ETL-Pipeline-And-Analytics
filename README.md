ğŸ“˜ Project Overview

The YouTube Streaming ETL Pipeline is a real-time, production-ready data engineering project designed to continuously extract, transform, and load YouTube video and channel data using modern big data tools.

This Pipeline follows best practices in stream processing, fault tolerance, schema validation, and distributed analytics.


ğŸ› ï¸ Core Technologies
Tools | Role

ğŸ§  YouTube Data API | Data Source (Videos + Channels)
ğŸ›°ï¸ Apache Kafka | Real-time Streaming Layer
ğŸ”¥ Apache Spark PySpark | Stream Consumer + Transformation
ğŸ—ƒï¸ Apache Hadoop HDFS (Parquet) | Scalable Data Lake Storage
ğŸ§© JSON | Local deduplication state
# Anaconda Jupyter Notebook | Data Analysis


ğŸš€ Key Features

âœ… Initial Load: Fetches up to 50 videos per channel
ğŸ” Streaming Poll: Extracts new uploads every 10 minutes
ğŸ“¡ Kafka Integration: Seamless producer/consumer model
ğŸ§ª Spark Processing: Schema validation & transformation
ğŸ“ HDFS Parquet Output: Analytics-ready, columnar storage
ğŸš« Duplicate Prevention: Via seen_video_ids.json
ğŸ“Š Data Analytics Highlights

After successfully ingesting data into HDFS using the streaming ETL pipeline, we conducted exploratory data analysis using PySpark, Pandas, and Matplotlib in Jupyter Notebook (data_analysis.ipynb). The goal was to generate meaningful insights from real YouTube content and enhance visibility into media trends.
ğŸ” Key Analysis Techniques:

  ğŸ“Œ Top Video Analysis: Ranking videos by view count, likes, and comment activity.

    
  ğŸ’¬ Comment Insights:

   * Fetched top-level comments per video

   * Extracted common keywords using text preprocessing

  â˜ï¸ Word Cloud Generation:
   
   * Built word clouds from video titles, tags, and comments

   * Highlighted trending keywords and viewer themes

  ğŸ“ˆ Visualizations:

   * Bar charts, pie charts, and line plots to explore:

     * Most active channels

     * Engagement over time

     * Content format popularity

These analyses not only showcase the depth of data collected but also help inform strategies for content optimization, user engagement, and machine learning integration.




ğŸ”— Data Flow (Simplified Architecture)

YouTube API â†’ Kafka Producer (Python) â†’ Kafka Topic
                        â†“
              Kafka Consumer (PySpark)
                        â†“
                   HDFS (Parquet)




ğŸ“Š Real-World Use Cases

  *  Track newly uploaded videos in near real-time

  *  Analyze comment engagement and sentiment

  *  Visualize accessibility insights (e.g., captioned content)

  *  Feed ML models with video metadata (quality, tags, etc.)











